{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The fake news project by Noah Wenneberg Junge, Kevin Mark Lock and Marcus Friis-Hansen"
      ],
      "metadata": {
        "id": "joVXlprjfikz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "This is our code for the fake news project. We have tried to keep as much as we could, though a small portion of specific values and small test of irrelevant classifier models and code have been lost due to editing the values/parameters or deleting/not saving it properly.\n",
        "\n",
        "We have tried to structure the document as the project linearly and also saving as many of the models and we made.\n",
        "\n",
        "Node that this document can be, but is not meant to be run all at once, and will probably result in a memory error. We made sure to run small portions of the code at a time and save the results for future loading. In the \"Setting Up\" section are all the imports and setting, to be able to run most of the sections by themselves."
      ],
      "metadata": {
        "id": "8UStYGBjCUKt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFpETDgIwvLn"
      },
      "source": [
        "\n",
        "# Setting Up\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"/content/drive/MyDrive/Data/\""
      ],
      "metadata": {
        "id": "PB5xNpxrS9kv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMASzAXFxNtK"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_0KxsAEw1vh"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jgqhDyGwuXr"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uy0217nxw9nx"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import *\n",
        "from nltk.stem.porter import *\n",
        "\n",
        "import pandas as pd\n",
        "from pandas import value_counts\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "from dataclasses import dataclass\n",
        "import  matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import scipy.sparse as sp\n",
        "from scipy.sparse import save_npz, load_npz\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "\n",
        "import joblib\n",
        "\n",
        "from scipy.sparse import csr_matrix, hstack, vstack\n",
        "\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4f6twf2aQLH"
      },
      "source": [
        "## Grouping labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzhPVLovaQLJ"
      },
      "outputs": [],
      "source": [
        "fakes = ['unreliable', 'fake', 'conspiracy', 'bias','junksci', 'satire','state']\n",
        "reliables = [\"reliable\", \"political\", \"clickbait\", 'caution', 'hate']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4sRBVEgaQLK"
      },
      "source": [
        "# Part 1: Data Processing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_XbrkG4aQLL"
      },
      "source": [
        "### Task 1: Cleaning Functions and testing on News Sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDVocXRjaQLL"
      },
      "source": [
        "Cleaning functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-cFSs66aQLM"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "\n",
        "urlEx = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "emailEx = re.compile(r'\\\\b[\\\\w.-]+?@\\\\w+?\\\\.\\\\w{2,4}\\\\b')\n",
        "numberEx = re.compile(r'[0-9]+\\.?[0-9]+(th)?')\n",
        "dateEx = re.compile(r'\\\\b[0-9]{4}-?[0-9]{2}-?[0-9]{2}\\\\b')\n",
        "englishGrammarEx = re.compile(r'\\'(\\w+)\\b')\n",
        "nonCharEx = re.compile(r'[^<>a-zA-ZÀ-ž\\-]')\n",
        "spacesEx = re.compile(r'[\\n\\s]+')\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "#Tokenize text\n",
        "def tokenize(txt):\n",
        "    txt = str(txt) if txt is not None else \"\"\n",
        "    #tokenize\n",
        "    txt = txt.lower()\n",
        "    txt = urlEx.sub(' <URL> ', txt) # Replace URL\n",
        "    txt = emailEx.sub(' <EMAIL> ', txt) # Replace email\n",
        "    txt = numberEx.sub(' <NUM> ', txt) # Replace number\n",
        "    txt = dateEx.sub(' <DATE> ', txt) # Replace Date\n",
        "    txt = englishGrammarEx.sub (\" \", txt)# Replace dumb english grammar\n",
        "    txt = nonCharEx.sub ( \" \", txt) # Replace Any non character remaining\n",
        "    txt = spacesEx.sub ( \" \", txt) # Replace Newline and double space\n",
        "\n",
        "\n",
        "    word_tokens = txt.split()\n",
        "\n",
        "    return word_tokens\n",
        "\n",
        "#Remove stopwords\n",
        "def stopWordRemove(word_tokens):\n",
        "    #remove stop words\n",
        "    noStopWords = [i for i in word_tokens if not (i in stop_words)]\n",
        "    return noStopWords\n",
        "\n",
        "#Stem\n",
        "def stem(word_tokens):\n",
        "    #stemming\n",
        "    singles = [stemmer.stem(w) for w in word_tokens]\n",
        "    return singles\n",
        "\n",
        "# Cleandata pipeline\n",
        "def clean_data_pipeline(txt):\n",
        "    txt = tokenize(txt)\n",
        "    txt = stopWordRemove(txt)\n",
        "    txt = stem(txt)\n",
        "    return txt\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4sTR7EtaQLN"
      },
      "source": [
        "Test on sample:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfuDszjYaQLO"
      },
      "outputs": [],
      "source": [
        "news_sample = pd.read_csv(DATA_PATH + \"news_sample.csv\")\n",
        "cleaned = news_sample[\"content\"].progress_apply"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_kQ7EG_aQLQ"
      },
      "source": [
        "### Task 2: Explore the FakeNewsCorpus"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################## Retrieve small sample to explore\n",
        "dataChunkToExplore = pd.read_csv(DATA_PATH + \"995Data.csv\", iterator=True).get_chunk(50000)\n",
        "#dataChunkToExplore = pd.read_csv(\"0.5Data.csv\") #for testing"
      ],
      "metadata": {
        "id": "7cgEfgtxuaWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply pipline to data sample\n",
        "dataChunkToExplore[\"tokenized\"] = dataChunkToExplore[\"content\"].progress_apply(tokenize)"
      ],
      "metadata": {
        "id": "YqfQzxZ5uuVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ph8SntQZaQLR"
      },
      "outputs": [],
      "source": [
        "dataChunkToExplore[\"cleaned\"] = dataChunkToExplore[\"content\"].progress_apply(clean_data_pipeline)\n",
        "dataChunkToExplore = dataChunkToExplore[dataChunkToExplore['type'].isin(reliables)|dataChunkToExplore['type'].isin(fakes)]#remove rows with missing values or 'unknown'-label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkLNlyq4aQLR"
      },
      "source": [
        "Some useful functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3z9cDTPPaQLS"
      },
      "outputs": [],
      "source": [
        "#Make vocabluary\n",
        "def computeUniqueWords(column):\n",
        "    flattened = [i for row in column for i in row]\n",
        "    return pd.DataFrame(flattened).value_counts()\n",
        "\n",
        "#plotting function\n",
        "def plot(x, y, title, xLabel = \"Category\", yLabel = \"Count\"):\n",
        "    # Create a bar chart\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    plt.bar(x, y)\n",
        "    plt.xlabel(xLabel)\n",
        "    plt.ylabel(yLabel)\n",
        "    plt.title(title)\n",
        "    plt.xticks(rotation=90)  # Rotate x-axis labels for readability\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plotRangeWords(data : pd.DataFrame, columnName, customTxt = \"\", range=[0, 100]):\n",
        "\n",
        "    df = pd.DataFrame(computeUniqueWords(data[columnName]))\n",
        "    df.columns = [\"count\"]\n",
        "    df = df.sort_values(\"count\", ascending=False)\n",
        "    df = df.reset_index(names=[\"Category\"])\n",
        "    # Get the top 100 counts\n",
        "\n",
        "    top_in_range = df.iloc[range[0]:range[1]]  # Assuming you have more than 100 counts\n",
        "    sum = df[\"count\"].sum()\n",
        "    top_in_range.loc[:, \"count\"] = top_in_range[\"count\"].apply(lambda x: x/sum)\n",
        "\n",
        "    plot(top_in_range[\"Category\"],top_in_range['count'], f'Top {range[0]} - {range[1]} Counts for ' + str(columnName)+ f\" ({customTxt})\" )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDkAvABAaQLS"
      },
      "outputs": [],
      "source": [
        "plotRangeWords(dataChunkToExplore, \"tokenized\", range=[0, 100])\n",
        "plotRangeWords(dataChunkToExplore, \"cleaned\", range=[0, 100])\n",
        "plotRangeWords(dataChunkToExplore, \"cleaned\", range=[1, 101])\n",
        "\n",
        "tokenizedValues = computeUniqueWords(dataChunkToExplore[\"tokenized\"])\n",
        "links = tokenizedValues[\"<URL>\"] if \"<URL>\" in tokenizedValues.index else 0\n",
        "dates = tokenizedValues[\"<DATE>\"] if \"<DATE>\" in tokenizedValues.index else 0\n",
        "nums = tokenizedValues[\"<NUM>\"] if \"<NUM>\" in tokenizedValues.index else 0\n",
        "\n",
        "print(f'Number of links in all documents: \\t{links}')\n",
        "print(f'Number of dates in all documents: \\t{dates}')\n",
        "print(f'Number of numbers in all documents: \\t{nums}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ti-FU1djaQLT"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plotTop10000Words(data, columnName):\n",
        "    df = pd.DataFrame(computeUniqueWords(data[columnName]))\n",
        "    df.columns = [\"count\"]\n",
        "    df = df.sort_values(\"count\", ascending=False)\n",
        "    df = df.reset_index(names=[\"Category\"])\n",
        "    # Get the top 100 counts\n",
        "    top_10000_df = df.head(10000)  # Assuming you have more than 100 counts\n",
        "\n",
        "    plot (range(1, len(top_10000_df) + 1), top_10000_df['count'], 'Top 10.000 Counts for ' + str(columnName))\n",
        "\n",
        "plotTop10000Words(dataChunkToExplore, \"tokenized\")\n",
        "plotTop10000Words(dataChunkToExplore, \"cleaned\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_NmLvWbaQLT"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "fakeData = dataChunkToExplore[dataChunkToExplore[\"type\"].isin(fakes)]\n",
        "relData = dataChunkToExplore[dataChunkToExplore[\"type\"].isin(reliables)]\n",
        "plotRangeWords(fakeData, \"cleaned\", customTxt=\"fake\", range=[1, 100])\n",
        "plotRangeWords(relData, \"cleaned\", customTxt=\"rel\", range=[1, 100])\n",
        "plotRangeWords(fakeData, \"cleaned\", customTxt=\"fake\", range=[150, 250])\n",
        "plotRangeWords(relData, \"cleaned\", customTxt=\"rel\", range=[150, 250])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qN3OWieJaQLT"
      },
      "outputs": [],
      "source": [
        "\n",
        "# make value counts\n",
        "fakeValueCounts = pd.DataFrame(computeUniqueWords(fakeData[\"cleaned\"]))\n",
        "fakeValueCounts.columns = [\"count\"]\n",
        "fakeValueCounts = fakeValueCounts.sort_values(\"count\", ascending=False)\n",
        "\n",
        "relValueCounts = pd.DataFrame(computeUniqueWords(relData[\"cleaned\"]))\n",
        "relValueCounts.columns = [\"count\"]\n",
        "relValueCounts = relValueCounts.sort_values(\"count\", ascending=False)\n",
        "\n",
        "datachunkValueCounts = pd.DataFrame(computeUniqueWords(dataChunkToExplore[\"cleaned\"]))\n",
        "datachunkValueCounts.columns = [\"count\"]\n",
        "datachunkValueCounts = datachunkValueCounts.sort_values(\"count\", ascending=False)\n",
        "\n",
        "# range to use (if range is [0, 500] it takes the top  500 words for fake plus the top 500 words for rel and conbines them, making)\n",
        "rangeUsed = [0, 500]\n",
        "data_range = pd.concat([fakeValueCounts.iloc[rangeUsed[0]:rangeUsed[1]], relValueCounts.iloc[rangeUsed[0]:rangeUsed[1]] ] )\n",
        "data_range = data_range.reset_index()\n",
        "data_range.columns = [\"word\", \"count\"]\n",
        "data_range = pd.DataFrame(data_range.groupby('word', as_index=False)['count'].sum())\n",
        "data_range = data_range.sort_values(\"count\", ascending=False)\n",
        "data_range = data_range.set_index(\"word\")\n",
        "\n",
        "\n",
        "# Since data_range is combined from two valueCount dataframes, there might be overlap between the words used. Chatgpt fix it here:\n",
        "\n",
        "\n",
        "differenceFrame = pd.DataFrame(columns = [\"word\", \"diff\", \"absDiff\"])\n",
        "for i in range(0, len(data_range)):\n",
        "    # Get the word\n",
        "\n",
        "    word = str(data_range.index[i])\n",
        "\n",
        "    # find count for each\n",
        "    fakeWordCount = fakeValueCounts.loc[word][\"count\"][0] if word in fakeValueCounts.index else 0\n",
        "    relWordCount = relValueCounts.loc[word][\"count\"][0] if word in relValueCounts.index else 0\n",
        "\n",
        "    # find difference in frequency and append it\n",
        "    difference = (1+relWordCount/relValueCounts.sum())/(1+fakeWordCount/fakeValueCounts.sum())\n",
        "    logDiff = np.log(float(difference)) # red line but works in runtime. Pylance cannot see it is a float in advance\n",
        "    newRow = pd.DataFrame({\"word\" : [word], \"diff\": [logDiff], \"absDiff\" : [abs(logDiff)]})\n",
        "    differenceFrame = pd.concat([differenceFrame, newRow])\n",
        "\n",
        "\n",
        "def plotDifferenceFrame(topN, frame, title):\n",
        "    topNFrame = differenceFrame.head(topN)\n",
        "    plot(topNFrame[\"word\"], topNFrame[\"diff\"], title, xLabel=\"Word\", yLabel=\"log(relCount / fakeCount)\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uk6lBfgPaQLU"
      },
      "outputs": [],
      "source": [
        "#Now we can make the graphs. We have decided to make 3 different graphs to see three different patters:\n",
        "differenceFrame = differenceFrame.sort_values(\"absDiff\", ascending = False)\n",
        "plotDifferenceFrame(100, differenceFrame, \"Top diferences in freq\")\n",
        "\n",
        "differenceFrame = differenceFrame.sort_values(\"diff\", ascending = False)\n",
        "plotDifferenceFrame(100, differenceFrame, \"Top words where difference is reliable-sided\")\n",
        "\n",
        "differenceFrame = differenceFrame.sort_values(\"diff\", ascending = True)\n",
        "plotDifferenceFrame(100, differenceFrame.sort_values(\"diff\", ascending = True), \"Top words where difference is fake-sided\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBYQ6FEBaQLU"
      },
      "source": [
        "When looking at the top words in these graphs there are some clear patterns. Reliable articles tend to use more words that points to a source like \"mr\", \"said\", \"newsletter\" etc and talking about stuff. They talk about stuff, that is happening without using strongly emotional words. They use words like \"court, iran, student, children\" etc, that are not so emotional. Also, reliable articles use far more numbers than fake ones, also tending to the pattern of having sources, statistics and outside knowledge.\n",
        "\n",
        "Comparing to the top words that fake articles use are very exaturated like \"nuclear\", \"parasite\", \"kill\", \"gun\" etc. These are emotional words, that probably triggers emotions in people making them likely to react in certain ways.\n",
        "\n",
        "There is a clear pattern in what words are used in each category."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boksplot of length of articles"
      ],
      "metadata": {
        "id": "GGCdVafFvCqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################## Retrieve small sample to explore\n",
        "boks = pd.read_csv(DATA_PATH + \"995Data.csv\")\n",
        "#dataChunkToExplore = pd.read_csv(\"0.5Data.csv\") #for testing"
      ],
      "metadata": {
        "id": "fVOHg73vvBuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply pipline to data sample\n",
        "boks[\"tokenized\"] = boks[\"content\"].progress_apply(tokenize)"
      ],
      "metadata": {
        "id": "fMuetEGFvBuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boks = dataChunkToExplore"
      ],
      "metadata": {
        "id": "JK2M3iRjvvsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boks[\"lengths\"] = boks[\"tokenized\"].progress_apply(lambda tokens : len(tokens))"
      ],
      "metadata": {
        "id": "lKGA9Zz8vPOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create a boxplot for the 'lengths' column\n",
        "boks.boxplot(column=\"lengths\", showfliers=False)"
      ],
      "metadata": {
        "id": "ivldz4D8w0Do"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnXoJmrFaQLU"
      },
      "source": [
        "### Task 3: Clean entire Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "chunksize = 500\n",
        "dataChunk = pd.DataFrame(columns=[\"type\", \"cleaned\"])\n",
        "tqdm.pandas()\n",
        "with tqdm(total=995000, desc=\"Cleaning Progress\") as pbar:\n",
        "  for i, chunk in enumerate(pd.read_csv(DATA_PATH + \"995Data.csv\", chunksize=chunksize, dtype=object)):\n",
        "      new = pd.DataFrame(columns=[\"type\", \"cleaned\"])\n",
        "      new[\"type\"] = chunk[\"type\"]\n",
        "      new['cleaned'] = chunk['content'].apply(clean_data_pipeline)\n",
        "\n",
        "      # Save the cleaned chunk if needed\n",
        "      dataChunk = pd.concat([dataChunk, new])\n",
        "      pbar.update(chunksize)\n",
        "\n",
        "try:\n",
        "    dataChunk.to_parquet(DATA_PATH +\"cleaned995DataReal.parquet\")\n",
        "    print(\"yes\")\n",
        "except:\n",
        "    print(\"no\")"
      ],
      "metadata": {
        "id": "LqyC8WnqS074"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXpqttTwaQLU"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "chunksize = 500\n",
        "dataChunk = pd.DataFrame(columns=[\"type\", \"cleaned\", \"domain\"])\n",
        "tqdm.pandas()\n",
        "with tqdm(total=995000, desc=\"Cleaning Progress\") as pbar:\n",
        "  for i, chunk in enumerate(pd.read_csv(DATA_PATH +\"995Data.csv\", chunksize=chunksize, dtype=object)):\n",
        "      new = pd.DataFrame(columns=[\"type\", \"cleaned\"])\n",
        "      new[\"type\"] = chunk[\"type\"]\n",
        "      new[\"domain\"] = chunk[\"domain\"]\n",
        "      new['cleaned'] = chunk['content'].apply(lambda txt : stopWordRemove(tokenize(txt)))\n",
        "\n",
        "      # Save the cleaned chunk if needed\n",
        "      dataChunk = pd.concat([dataChunk, new])\n",
        "      pbar.update(chunksize)\n",
        "\n",
        "try:\n",
        "    dataChunk.to_parquet(DATA_PATH + \"notStemmedWithDomain.parquet\")\n",
        "    print(\"yes\")\n",
        "except:\n",
        "    print(\"no\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaGsGwvL9DTF"
      },
      "outputs": [],
      "source": [
        "data = pd.read_parquet(DATA_PATH +\"cleaned995DataReal.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "es32IqgJ_mY3"
      },
      "outputs": [],
      "source": [
        "data_notStemmed = pd.read_parquet(DATA_PATH +\"notStemmedWithDomain.parquet\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anLx39dKmq4n"
      },
      "outputs": [],
      "source": [
        "def grouping_rules(label):\n",
        "    if label in fakes:\n",
        "        return 1\n",
        "    elif label in reliables:\n",
        "        return 0\n",
        "    else:\n",
        "        raise Exception(\"Label is not in either fakes or reliables\")\n",
        "\n",
        "\n",
        "# This removes any row, that has a cleaned-list of length 5 or fewer.\n",
        "# Then it removes any row with type that we are not taking into account eg. unknown, missing etc.\n",
        "# Finaly applying grouping rule, making fake = 1 and reliable = 0\n",
        "def removeAndGroupingRule(df):\n",
        "  df = df[df['cleaned'].apply(lambda x: len(x) > 5)]\n",
        "  df = df[df['type'].isin(reliables) | df['type'].isin(fakes)]\n",
        "  df = df.reset_index(drop=True)\n",
        "  df[\"type\"] = df[\"type\"].apply(grouping_rules)\n",
        "  return df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fW-kFJlZ05Ik"
      },
      "outputs": [],
      "source": [
        "data = removeAndGroupingRule(data)\n",
        "data_notStemmed = removeAndGroupingRule(data_notStemmed)\n",
        "print(len(data))\n",
        "print(len(data_notStemmed))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDxnZIEnaQLU"
      },
      "source": [
        "### Task 4 Split the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XAWfv4H_1My"
      },
      "outputs": [],
      "source": [
        "X = np.array(data[\"cleaned\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddBYDVD3AF-a"
      },
      "outputs": [],
      "source": [
        "X_notStemmed = np.array(data_notStemmed[\"cleaned\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "domains = np.array(data_notStemmed[\"domain\"])"
      ],
      "metadata": {
        "id": "H92d63Q1GUq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkK5l8xnAJiu"
      },
      "outputs": [],
      "source": [
        "y = data[\"type\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFBhk4Oz9WK_"
      },
      "outputs": [],
      "source": [
        "#first split data into training(80%) and other(20%)\n",
        "X_train, X_other, X_train_notStemmed, X_other_notStemmed, y_train, y_other, domains_train, domains_other = train_test_split(X, X_notStemmed, y, domains, random_state=0,test_size=0.20)\n",
        "\n",
        "#second split to split other into validation(10%) and test(10%)\n",
        "X_val, X_test, X_val_notStemmed, X_test_notStemmed, y_val, y_test, domains_val, domains_test = train_test_split(X_other, X_other_notStemmed, y_other, domains_other,  random_state= 0 , test_size= 0.50,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loJMID1d1wEr"
      },
      "outputs": [],
      "source": [
        "\n",
        "np.savez(\n",
        "    DATA_PATH +'dataSplitted.npz',\n",
        "    X_train=X_train,\n",
        "    X_train_notStemmed=X_train_notStemmed,\n",
        "    y_train=y_train,\n",
        "    X_val=X_val,\n",
        "    X_val_notStemmed=X_val_notStemmed,\n",
        "    y_val=y_val,\n",
        "    X_test=X_test,\n",
        "    X_test_notStemmed=X_test_notStemmed,\n",
        "    y_test=y_test\n",
        ")\n",
        "\n",
        "np.savez(\n",
        "    DATA_PATH +'domains.npz',\n",
        "    domains_train=domains_train,\n",
        "    domains_val=domains_val,\n",
        "    domains_test=domains_test,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEYhy5aLaQLV"
      },
      "source": [
        "# Part 2: Simple Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3iZ3dW4z9iS"
      },
      "source": [
        "## Make BoW vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0OWCV-kCBqU"
      },
      "outputs": [],
      "source": [
        "dataSplitted = np.load(DATA_PATH +'dataSplitted.npz', allow_pickle=True)\n",
        "X_train = dataSplitted[\"X_train\"]\n",
        "X_val = dataSplitted[\"X_val\"]\n",
        "X_test = dataSplitted[\"X_test\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMuYT1DkaQLV"
      },
      "source": [
        "For our simple vector, we will use a simple BoW vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZU-ySZKNHpdq"
      },
      "outputs": [],
      "source": [
        "X_train_joined = np.array(pd.DataFrame(X_train)[0].progress_apply(lambda tokens: ' '.join(tokens)))\n",
        "X_val_joined = np.array(pd.DataFrame(X_val)[0].progress_apply(lambda tokens: ' '.join(tokens)))\n",
        "X_test_joined = np.array(pd.DataFrame(X_test)[0].progress_apply(lambda tokens: ' '.join(tokens)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JP9uIiK9aQLV"
      },
      "outputs": [],
      "source": [
        "vectorizer = CountVectorizer(min_df=0.01)\n",
        "\n",
        "vectorizer.fit(X_train_joined)\n",
        "\n",
        "bow_train = vectorizer.transform(X_train_joined)\n",
        "bow_val = vectorizer.transform(X_val_joined)\n",
        "bow_test = vectorizer.transform(X_test_joined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DyItXluVDoli"
      },
      "outputs": [],
      "source": [
        "joblib.dump({\n",
        "    'bow_vectorizer' : vectorizer,\n",
        "    'bow_train': bow_train,\n",
        "    'bow_val': bow_val,\n",
        "    'bow_test': bow_test\n",
        "}, DATA_PATH +'bow.joblib')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLIRYlp60dq2"
      },
      "source": [
        "## Preprocessesing Scraped Articles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bKCH_bT0PBe"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEBeH7NU9RKr"
      },
      "source": [
        "### Model 0: Forest classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FO6gMkv99RKs"
      },
      "outputs": [],
      "source": [
        "dataSplitted = np.load(DATA_PATH +'dataSplitted.npz', allow_pickle=True)\n",
        "bow = joblib.load(DATA_PATH +\"bow.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_WcCxte9RKu"
      },
      "outputs": [],
      "source": [
        "X_train = bow[\"bow_train\"]\n",
        "X_val = bow[\"bow_val\"]\n",
        "X_test = bow[\"bow_test\"]\n",
        "\n",
        "y_train = dataSplitted[\"y_train\"]\n",
        "y_val = dataSplitted[\"y_val\"]\n",
        "y_test = dataSplitted[\"y_test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2DALMz99RKv"
      },
      "outputs": [],
      "source": [
        "model0_simple = RandomForestClassifier(max_depth=20, random_state=0)\n",
        "model0_simple.fit(X_train[0: 40000], y_train[0:40000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_BPFNiz9RKv"
      },
      "outputs": [],
      "source": [
        "#make prediction\n",
        "y_pred = model0_simple.predict(X_val)\n",
        "y_pred = np.rint(y_pred)\n",
        "\n",
        "\n",
        "\n",
        "print(\"accuracy: \", accuracy_score(y_val, y_pred))\n",
        "print(\"precision: \", precision_score(y_val, y_pred, average=\"binary\"))\n",
        "print(\"recall: \", recall_score(y_val, y_pred, average=\"binary\"))\n",
        "print(\"f1: \", f1_score(y_val, y_pred, average=\"binary\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(model0_simple, DATA_PATH +\"model0_simple.joblib\")"
      ],
      "metadata": {
        "id": "niBA3CeYb-pK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nu2TyfeJ0CRM"
      },
      "source": [
        "### Model 1: Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iby2fxpiqWIa"
      },
      "outputs": [],
      "source": [
        "dataSplitted = np.load(DATA_PATH + 'dataSplitted.npz', allow_pickle=True)\n",
        "bow = joblib.load(DATA_PATH + \"bow.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RamyCABVqWIo"
      },
      "outputs": [],
      "source": [
        "X_train = bow[\"bow_train\"]\n",
        "X_val = bow[\"bow_val\"]\n",
        "X_test = bow[\"bow_test\"]\n",
        "\n",
        "y_train = dataSplitted[\"y_train\"]\n",
        "y_val = dataSplitted[\"y_val\"]\n",
        "y_test = dataSplitted[\"y_test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTfUP58pqWIq"
      },
      "outputs": [],
      "source": [
        "model1_simple = LinearRegression()\n",
        "model1_simple.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RO6zXAjtqWIt"
      },
      "outputs": [],
      "source": [
        "#make prediction\n",
        "y_pred = model1_simple.predict(X_val)\n",
        "y_pred = np.clip(np.rint(y_pred), 0, 1)\n",
        "\n",
        "\n",
        "\n",
        "print(\"accuracy: \", accuracy_score(y_val, y_pred))\n",
        "print(\"precision: \", precision_score(y_val, y_pred, average=\"binary\"))\n",
        "print(\"recall: \", recall_score(y_val, y_pred, average=\"binary\"))\n",
        "print(\"f1: \", f1_score(y_val, y_pred, average=\"binary\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(model1_simple, DATA_PATH + \"model1_simple.joblib\")"
      ],
      "metadata": {
        "id": "uJcL3SHAAh2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksS8574-0UfA"
      },
      "source": [
        "### Model 2: Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVjx1UpCLHZe"
      },
      "outputs": [],
      "source": [
        "dataSplitted = np.load(DATA_PATH +'dataSplitted.npz', allow_pickle=True)\n",
        "bow = joblib.load(DATA_PATH +\"bow.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8AR9mKyLKJS"
      },
      "outputs": [],
      "source": [
        "X_train = bow[\"bow_train\"]\n",
        "X_val = bow[\"bow_val\"]\n",
        "X_test = bow[\"bow_test\"]\n",
        "\n",
        "y_train = dataSplitted[\"y_train\"]\n",
        "y_val = dataSplitted[\"y_val\"]\n",
        "y_test = dataSplitted[\"y_test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ff_Uoxk8aQLW"
      },
      "outputs": [],
      "source": [
        "model2_simple = LogisticRegression(max_iter=300, verbose=100)\n",
        "model2_simple.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sh6cRai6aQLX"
      },
      "outputs": [],
      "source": [
        "#make prediction\n",
        "y_pred = model2_simple.predict(X_val)\n",
        "y_pred = np.rint(y_pred)\n",
        "\n",
        "print(\"accuracy: \", accuracy_score(y_val, y_pred))\n",
        "print(\"precision: \", precision_score(y_val, y_pred, average=\"binary\"))\n",
        "print(\"recall: \", recall_score(y_val, y_pred, average=\"binary\"))\n",
        "print(\"f1: \", f1_score(y_val, y_pred, average=\"binary\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(model2_simple, DATA_PATH +\"model2_simple.joblib\")"
      ],
      "metadata": {
        "id": "lZet-M_bhe8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "final test"
      ],
      "metadata": {
        "id": "gerq9enbJJyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2_simple = joblib.load(DATA_PATH + \"model2_simple.joblib\")"
      ],
      "metadata": {
        "id": "s_qWEJ8wJDGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bm3AxPrIJLW2"
      },
      "outputs": [],
      "source": [
        "#make prediction\n",
        "y_pred = model2_simple.predict(X_test)\n",
        "y_pred = np.rint(y_pred)\n",
        "\n",
        "print(\"accuracy: \", accuracy_score(y_test, y_pred))\n",
        "print(\"precision: \", precision_score(y_test, y_pred, average=\"binary\"))\n",
        "print(\"recall: \", recall_score(y_test, y_pred, average=\"binary\"))\n",
        "print(\"f1: \", f1_score(y_test, y_pred, average=\"binary\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCdgSINk0t8o"
      },
      "source": [
        "### Model 3: Adding scraped Articles"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scraped = pd.read_csv(\"/content/drive/MyDrive/Data/BBC_scraped.csv\")[[\"Content\"]]\n",
        "\n",
        "scraped.columns = [\"content\"]\n",
        "scraped[\"type\"] = 0\n",
        "scraped[\"cleaned\"] = scraped[\"content\"].progress_apply(clean_data_pipeline)"
      ],
      "metadata": {
        "id": "Fcqo56QjADLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bow_vectorizer = joblib.load(\"/content/drive/MyDrive/Data/bow.joblib\")[\"bow_vectorizer\"]\n"
      ],
      "metadata": {
        "id": "-ELAAnNwCe-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scraped_joined = np.array(scraped[\"cleaned\"].progress_apply(lambda tokens: ' '.join(tokens)))\n",
        "\n",
        "bow_scraped = bow_vectorizer.transform(scraped_joined)"
      ],
      "metadata": {
        "id": "1rqjcucNCzWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump({\"data\" :  scraped, \"bow\" : bow_scraped}, \"/content/drive/MyDrive/Data/scraped_cleaned.joblib\")"
      ],
      "metadata": {
        "id": "Uq9ZmjnpCC4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scraped = joblib.load(\"/content/drive/MyDrive/Data/scraped_cleaned.joblib\")"
      ],
      "metadata": {
        "id": "0TGJ6CowSMwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97UNk-aySncp"
      },
      "outputs": [],
      "source": [
        "dataSplitted = np.load('/content/drive/MyDrive/Data/dataSplitted.npz', allow_pickle=True)\n",
        "bow = joblib.load(\"/content/drive/MyDrive/Data/bow.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WblMv6eSSncr"
      },
      "outputs": [],
      "source": [
        "X_train = vstack([bow[\"bow_train\"], scraped[\"bow\"]])\n",
        "X_val = bow[\"bow_val\"]\n",
        "X_test = bow[\"bow_test\"]\n",
        "\n",
        "\n",
        "y_train = np.concatenate((dataSplitted[\"y_train\"], scraped[\"data\"][\"type\"]), axis = 0)\n",
        "y_val = dataSplitted[\"y_val\"]\n",
        "y_test = dataSplitted[\"y_test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6F1e9OLLSncr"
      },
      "outputs": [],
      "source": [
        "model3_simple = LogisticRegression(max_iter=300, verbose=100)\n",
        "model3_simple.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1XdNlugSncs"
      },
      "outputs": [],
      "source": [
        "#make prediction\n",
        "y_pred = model3_simple.predict(X_val)\n",
        "y_pred = np.rint(y_pred)\n",
        "\n",
        "print(\"accuracy: \", accuracy_score(y_val, y_pred))\n",
        "print(\"precision: \", precision_score(y_val, y_pred, average=\"binary\"))\n",
        "print(\"recall: \", recall_score(y_val, y_pred, average=\"binary\"))\n",
        "print(\"f1: \", f1_score(y_val, y_pred, average=\"binary\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(model3_simple, \"/content/drive/MyDrive/Data/model3_simple.joblib\")"
      ],
      "metadata": {
        "id": "VI5-GB8RhoVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsqceovA0oBh"
      },
      "source": [
        "### Model 4: Adding domains"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naxHCkBH0Xnr"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIyE_jifZEZ9"
      },
      "source": [
        "We have done this before so we just load it:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LV64MVsaQLW"
      },
      "source": [
        "#### One hot encoding for domain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "domains = np.load('/content/drive/MyDrive/Data/domains.npz', allow_pickle=True)\n",
        "bow = joblib.load(\"/content/drive/MyDrive/Data/bow.joblib\")"
      ],
      "metadata": {
        "id": "GTnB37PXO_Vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataSplitted = np.load('/content/drive/MyDrive/Data/dataSplitted.npz', allow_pickle=True)"
      ],
      "metadata": {
        "id": "pLTpCd90P5xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7lTV2oiaQLW"
      },
      "outputs": [],
      "source": [
        "ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "\n",
        "doms_train = domains[\"domains_train\"].reshape(-1, 1)\n",
        "doms_val = domains[\"domains_val\"].reshape(-1, 1)\n",
        "doms_test = domains[\"domains_test\"].reshape(-1, 1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "oheDomainFitted = ohe.fit(doms_train)\n",
        "\n",
        "\n",
        "oh_train = np.array(oheDomainFitted.transform(doms_train))\n",
        "oh_val = np.array(oheDomainFitted.transform(doms_val))\n",
        "oh_test = np.array(oheDomainFitted.transform(doms_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gP3dNAHmQ_ZH"
      },
      "outputs": [],
      "source": [
        "\n",
        "bow_train = bow[\"bow_train\"]\n",
        "bow_val = bow[\"bow_val\"]\n",
        "bow_test = bow[\"bow_test\"]\n",
        "\n",
        "y_train = dataSplitted[\"y_train\"]\n",
        "y_val = dataSplitted[\"y_val\"]\n",
        "y_test = dataSplitted[\"y_test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMaE7HMjQ_ZI"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Combine the sparse matrices using hstack\n",
        "X_train = hstack([bow_train, csr_matrix(oh_train)])\n",
        "X_val = hstack([bow_val, csr_matrix(oh_val)])\n",
        "X_test = hstack([bow_test, csr_matrix(oh_test)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WD2ICxERtvB"
      },
      "outputs": [],
      "source": [
        "model4_simple = LogisticRegression(max_iter=300, verbose=100)\n",
        "model4_simple.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xM0szhFRtvC"
      },
      "outputs": [],
      "source": [
        "#make prediction\n",
        "y_pred = model4_simple.predict(X_val)\n",
        "\n",
        "\n",
        "print(\"accuracy: \", accuracy_score(y_val, y_pred))\n",
        "print(\"precision: \", precision_score(y_val, y_pred, average=\"binary\"))\n",
        "print(\"recall: \", recall_score(y_val, y_pred, average=\"binary\"))\n",
        "print(\"f1: \", f1_score(y_val, y_pred, average=\"binary\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(model4_simple, \"/content/drive/MyDrive/Data/model4_simple.joblib\")"
      ],
      "metadata": {
        "id": "j9xhWZIMiKG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgwSt5GDaQLW"
      },
      "source": [
        "### Simple Models\n",
        "\n",
        "Here we fit a few simple models on the data an compare what works and what doesnt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5nFwE6XaQLX"
      },
      "source": [
        "# Part 3: Advanced Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtCRsA0irBVi"
      },
      "source": [
        "## Make TFIDF Vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtEaee2CMy_j"
      },
      "outputs": [],
      "source": [
        "bow = joblib.load(DATA_PATH + \"bow.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZ7N9Iu7M4gf"
      },
      "outputs": [],
      "source": [
        "bow_train = bow[\"bow_train\"]\n",
        "bow_val = bow[\"bow_val\"]\n",
        "bow_test = bow[\"bow_test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkdVMdc-zcpu"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfTransformer()\n",
        "\n",
        "# This ensures that the IDF values only come from X_train, and data from test and validation does not leak into train data.\n",
        "vectorizer.fit(bow_train)\n",
        "\n",
        "tfidf_train = vectorizer.transform(bow_train)\n",
        "tfidf_val = vectorizer.transform(bow_val)\n",
        "tfidf_test = vectorizer.transform(bow_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FzPoy8BNY_0"
      },
      "outputs": [],
      "source": [
        "joblib.dump({\n",
        "    'tfidf_vectorizer' : vectorizer,\n",
        "    'tfidf_train': tfidf_train,\n",
        "    'tfidf_val': tfidf_val,\n",
        "    'tfidf_test': tfidf_test\n",
        "}, DATA_PATH + 'tfidf.joblib')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1: TFIDF Vector\n"
      ],
      "metadata": {
        "id": "qu8vwvaz2cM_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymawO7buYjWC"
      },
      "outputs": [],
      "source": [
        "dataSplitted = np.load(DATA_PATH + 'dataSplitted.npz', allow_pickle=True)\n",
        "tfidf = joblib.load(DATA_PATH + \"tfidf.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRmGkLVFYjWG"
      },
      "outputs": [],
      "source": [
        "X_train = tfidf[\"tfidf_train\"]\n",
        "X_val = tfidf[\"tfidf_val\"]\n",
        "X_test = tfidf[\"tfidf_test\"]\n",
        "\n",
        "y_train = dataSplitted[\"y_train\"]\n",
        "y_val = dataSplitted[\"y_val\"]\n",
        "y_test = dataSplitted[\"y_test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgSInLuTr4EQ"
      },
      "outputs": [],
      "source": [
        "model1 = LogisticRegression(max_iter=300, verbose=100)\n",
        "\n",
        "model1.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNG5OPYzr-q4"
      },
      "outputs": [],
      "source": [
        "#make prediction\n",
        "y_pred = model1.predict(X_val)\n",
        "\n",
        "print(\"accuracy: \", accuracy_score(y_val, y_pred))\n",
        "print(\"precision: \", precision_score(y_val, y_pred, average=\"binary\"))\n",
        "print(\"recall: \", recall_score(y_val, y_pred, average=\"binary\"))\n",
        "print(\"f1: \", f1_score(y_val, y_pred, average=\"binary\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final F1 test (Only Used Once)"
      ],
      "metadata": {
        "id": "Fo6Z8yJzECQ4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cChn7SyIEBkK"
      },
      "outputs": [],
      "source": [
        "#make prediction\n",
        "y_pred = model1.predict(X_test)\n",
        "\n",
        "print(\"accuracy: \", accuracy_score(y_test, y_pred))\n",
        "print(\"precision: \", precision_score(y_test, y_pred, average=\"binary\"))\n",
        "print(\"recall: \", recall_score(y_test, y_pred, average=\"binary\"))\n",
        "print(\"f1: \", f1_score(y_test, y_pred, average=\"binary\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlBi6gx-Sf-W"
      },
      "outputs": [],
      "source": [
        "joblib.dump(model1, DATA_PATH + \"model1_advanced.joblib\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuq_TfKNsNo_"
      },
      "source": [
        "## Model 2: Simple Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iMWWqVrOmqw"
      },
      "outputs": [],
      "source": [
        "dataSplitted = np.load(DATA_PATH + 'dataSplitted.npz', allow_pickle=True)\n",
        "tfidf = joblib.load(DATA_PATH + \"tfidf.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdGR-O8yOmq2"
      },
      "outputs": [],
      "source": [
        "X_train = tfidf[\"tfidf_train\"]\n",
        "X_val = tfidf[\"tfidf_val\"]\n",
        "X_test = tfidf[\"tfidf_test\"]\n",
        "\n",
        "y_train = dataSplitted[\"y_train\"]\n",
        "y_val = dataSplitted[\"y_val\"]\n",
        "y_test = dataSplitted[\"y_test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZHWhWtgse22"
      },
      "outputs": [],
      "source": [
        "model2 = MLPClassifier(verbose=True, solver='adam', hidden_layer_sizes=(5, 5), random_state=1, activation=\"relu\")\n",
        "model2.n_jobs = -1\n",
        "model2.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u78fmET_svK5"
      },
      "outputs": [],
      "source": [
        "#make prediction\n",
        "y_pred = model2.predict(X_val)\n",
        "\n",
        "\n",
        "print(\"accuracy: \", accuracy_score(y_val, y_pred))\n",
        "print(\"precision: \", precision_score(y_val, y_pred, average=\"binary\"))\n",
        "print(\"recall: \", recall_score(y_val, y_pred, average=\"binary\"))\n",
        "print(\"f1: \", f1_score(y_val, y_pred, average=\"binary\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final test"
      ],
      "metadata": {
        "id": "dDqn81DjEYKE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XOwJ05VEWug"
      },
      "outputs": [],
      "source": [
        "#make prediction\n",
        "y_pred = model2.predict(X_test)\n",
        "\n",
        "\n",
        "print(\"accuracy: \", accuracy_score(y_test, y_pred))\n",
        "print(\"precision: \", precision_score(y_test, y_pred, average=\"binary\"))\n",
        "print(\"recall: \", recall_score(y_test, y_pred, average=\"binary\"))\n",
        "print(\"f1: \", f1_score(y_test, y_pred, average=\"binary\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZpgVxku3Z8e"
      },
      "outputs": [],
      "source": [
        "joblib.dump(model2, DATA_PATH + \"model2_advanced.joblib\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6Rokoohs-Yx"
      },
      "source": [
        "## Model 3: Adding Nodes in layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEmUXXi1RU9P"
      },
      "outputs": [],
      "source": [
        "dataSplitted = np.load(DATA_PATH + 'dataSplitted.npz', allow_pickle=True)\n",
        "tfidf = joblib.load(DATA_PATH + \"tfidf.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wCmsBAORU9R"
      },
      "outputs": [],
      "source": [
        "X_train = tfidf[\"tfidf_train\"]\n",
        "X_val = tfidf[\"tfidf_val\"]\n",
        "X_test = tfidf[\"tfidf_test\"]\n",
        "\n",
        "y_train = dataSplitted[\"y_train\"]\n",
        "y_val = dataSplitted[\"y_val\"]\n",
        "y_test = dataSplitted[\"y_test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HogtFpgytLDu"
      },
      "outputs": [],
      "source": [
        "model3 = MLPClassifier(verbose=True, solver='adam', hidden_layer_sizes=(64, 64), random_state=1, activation=\"relu\")\n",
        "model3.n_jobs = -1\n",
        "model3.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jf-mMKXMtLDw"
      },
      "outputs": [],
      "source": [
        "y_pred = model3.predict(X_val)\n",
        "acc = accuracy_score(y_val, y_pred)\n",
        "\n",
        "print(\"accuracy: \", accuracy_score(y_val, y_pred))\n",
        "print(\"precision: \", precision_score(y_val, y_pred, average=\"binary\"))\n",
        "print(\"recall: \", recall_score(y_val, y_pred, average=\"binary\"))\n",
        "print(\"f1: \", f1_score(y_val, y_pred, average=\"binary\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "final test"
      ],
      "metadata": {
        "id": "yxgoGxd9ElQZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuzaxhI2EktD"
      },
      "outputs": [],
      "source": [
        "y_pred = model3.predict(X_test)\n",
        "acc = accuracy_score(y_val, y_pred)\n",
        "\n",
        "print(\"accuracy: \", accuracy_score(y_test, y_pred))\n",
        "print(\"precision: \", precision_score(y_test, y_pred, average=\"binary\"))\n",
        "print(\"recall: \", recall_score(y_test, y_pred, average=\"binary\"))\n",
        "print(\"f1: \", f1_score(y_test, y_pred, average=\"binary\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWUPQwbw5S7x"
      },
      "outputs": [],
      "source": [
        "joblib.dump(model3, DATA_PATH + \"model3_advanced.joblib\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrfGYkZIx9wD"
      },
      "source": [
        "## Make an Embedding vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uyk_KNkFH0w"
      },
      "outputs": [],
      "source": [
        "embeddingModel = KeyedVectors.load_word2vec_format(DATA_PATH + \"GoogleNews-vectors-negative300.bin\", binary=True, limit=1000000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4u-lFQ-F-Zm"
      },
      "outputs": [],
      "source": [
        "def documentEmbed(tokens):\n",
        "  vectorArray = [embeddingModel[i] if i in embeddingModel else np.zeros(300) for i in tokens]\n",
        "\n",
        "  mean = np.mean(vectorArray, axis=0)\n",
        "  if type(mean) is np.float64:\n",
        "    print(len(tokens))\n",
        "  return mean\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvVJ2awaTmK8"
      },
      "outputs": [],
      "source": [
        "dataSplitted = np.load(DATA_PATH + 'dataSplitted.npz', allow_pickle=True)\n",
        "X_train = dataSplitted[\"X_train_notStemmed\"]\n",
        "X_val = dataSplitted[\"X_val_notStemmed\"]\n",
        "X_test = dataSplitted[\"X_test_notStemmed\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8nxaMe4TXrY"
      },
      "outputs": [],
      "source": [
        "documentEmbeddings_train = np.vstack(pd.DataFrame(X_train)[0].progress_apply(documentEmbed).values)\n",
        "documentEmbeddings_val = np.vstack(pd.DataFrame(X_val)[0].progress_apply(documentEmbed).values)\n",
        "documentEmbeddings_test = np.vstack(pd.DataFrame(X_test)[0].progress_apply(documentEmbed).values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVJXAN0QTRU_"
      },
      "outputs": [],
      "source": [
        "\n",
        "joblib.dump({\n",
        "    'embeddings_train': documentEmbeddings_train,\n",
        "    'embeddings_val': documentEmbeddings_val,\n",
        "    'embeddings_test': documentEmbeddings_test\n",
        "}, DATA_PATH + 'embeddings.joblib')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOisDatotehF"
      },
      "source": [
        "## Model 4: Neural network with embedding vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKdn8oz2jDIT"
      },
      "outputs": [],
      "source": [
        "dataSplitted = np.load(DATA_PATH + 'dataSplitted.npz', allow_pickle=True)\n",
        "embeddings = joblib.load(DATA_PATH + \"embeddings.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDBHkQmxkPJ1"
      },
      "outputs": [],
      "source": [
        "X_train = embeddings[\"embeddings_train\"]\n",
        "X_val = embeddings[\"embeddings_val\"]\n",
        "X_test = embeddings[\"embeddings_test\"]\n",
        "\n",
        "y_train = dataSplitted[\"y_train\"]\n",
        "y_val = dataSplitted[\"y_val\"]\n",
        "y_test = dataSplitted[\"y_test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OD2p6a3rtzNK"
      },
      "outputs": [],
      "source": [
        "model4 = MLPClassifier(verbose=True, solver='adam', hidden_layer_sizes=(64, 64), random_state=1, activation=\"relu\")\n",
        "model4.n_jobs = -1\n",
        "model4.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ar-O-GnstzNL"
      },
      "outputs": [],
      "source": [
        "#make prediction\n",
        "y_pred = model4.predict(X_val)\n",
        "print(\"accuracy: \", accuracy_score(y_val, y_pred))\n",
        "print(\"precision: \", precision_score(y_val, y_pred, average=\"binary\"))\n",
        "print(\"recall: \", recall_score(y_val, y_pred, average=\"binary\"))\n",
        "print(\"f1: \", f1_score(y_val, y_pred, average=\"binary\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final test"
      ],
      "metadata": {
        "id": "lF_xM-6fE1Fe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gsBenSrEv4s"
      },
      "outputs": [],
      "source": [
        "#make prediction\n",
        "y_pred = model4.predict(X_test)\n",
        "print(\"accuracy: \", accuracy_score(y_test, y_pred))\n",
        "print(\"precision: \", precision_score(y_test, y_pred, average=\"binary\"))\n",
        "print(\"recall: \", recall_score(y_test, y_pred, average=\"binary\"))\n",
        "print(\"f1: \", f1_score(y_test, y_pred, average=\"binary\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Di9K0l65XKM"
      },
      "outputs": [],
      "source": [
        "joblib.dump(model4, DATA_PATH + \"model4_advanced.joblib\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgdcnXaOvroK"
      },
      "source": [
        "## N Average embeddings pr document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_pn5-Q5kuSR"
      },
      "outputs": [],
      "source": [
        "embeddingModel = KeyedVectors.load_word2vec_format(DATA_PATH + \"GoogleNews-vectors-negative300.bin\", binary=True, limit=1000000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ilg3u4V0vqfw"
      },
      "outputs": [],
      "source": [
        "def documentEmbedN(tokens, n):\n",
        "    tokenLength = len(tokens)\n",
        "    # Pad the token length to have a minimum length of n\n",
        "    if tokenLength < n:\n",
        "        padding = np.array([''] * (n - tokenLength))\n",
        "        tokens = np.concatenate((tokens, padding))\n",
        "        tokenLength = n\n",
        "\n",
        "    vectorArrays = []\n",
        "    for i in range(n):\n",
        "        start_index = int(i * tokenLength / n)\n",
        "        end_index = int((i + 1) * tokenLength / n)\n",
        "\n",
        "        vectorArray = [embeddingModel[token] if token in embeddingModel else np.zeros(300)\n",
        "                       for token in tokens[start_index:end_index]]\n",
        "        vectorArrays.append(vectorArray)\n",
        "\n",
        "    means = []\n",
        "    for vectorArray in vectorArrays:\n",
        "        mean = np.mean(vectorArray, axis=0)\n",
        "        means.append(mean)\n",
        "\n",
        "    documentEmbed = np.concatenate(means, axis=0)\n",
        "\n",
        "    return documentEmbed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiUQqMJgkkfT"
      },
      "outputs": [],
      "source": [
        "dataSplitted = np.load(DATA_PATH + 'dataSplitted.npz', allow_pickle=True)\n",
        "X_train = dataSplitted[\"X_train_notStemmed\"]\n",
        "X_val = dataSplitted[\"X_val_notStemmed\"]\n",
        "X_test = dataSplitted[\"X_test_notStemmed\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfCjBWfU4SHy"
      },
      "source": [
        "### 3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Il81buiLkkfb"
      },
      "outputs": [],
      "source": [
        "documentEmbeddings3_train = np.vstack(pd.DataFrame(X_train)[0].progress_apply(lambda tokens : documentEmbedN(tokens , 3)).values)\n",
        "documentEmbeddings3_val = np.vstack(pd.DataFrame(X_val)[0].progress_apply(lambda tokens : documentEmbedN(tokens , 3)).values)\n",
        "documentEmbeddings3_test = np.vstack(pd.DataFrame(X_test)[0].progress_apply(lambda tokens : documentEmbedN(tokens , 3)).values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jt264KRQ6-in"
      },
      "outputs": [],
      "source": [
        "documentEmbeddings3_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ytp9mwhbkkfd"
      },
      "outputs": [],
      "source": [
        "\n",
        "joblib.dump({\n",
        "    'embeddings3_train': documentEmbeddings3_train,\n",
        "    'embeddings3_val': documentEmbeddings3_val,\n",
        "    'embeddings3_test': documentEmbeddings3_test\n",
        "}, DATA_PATH + 'embeddings3.joblib')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDx1mYSY28rB"
      },
      "source": [
        "### 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t70Pl-EO28rJ"
      },
      "outputs": [],
      "source": [
        "documentEmbeddings6_train = np.vstack(pd.DataFrame(X_train)[0].progress_apply(lambda tokens : documentEmbedN(tokens , 6)).values)\n",
        "documentEmbeddings6_val = np.vstack(pd.DataFrame(X_val)[0].progress_apply(lambda tokens : documentEmbedN(tokens , 6)).values)\n",
        "documentEmbeddings6_test = np.vstack(pd.DataFrame(X_test)[0].progress_apply(lambda tokens : documentEmbedN(tokens , 6)).values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dz9dF73228rK"
      },
      "outputs": [],
      "source": [
        "\n",
        "joblib.dump({\n",
        "    'embeddings6_train': documentEmbeddings6_train,\n",
        "    'embeddings6_val': documentEmbeddings6_val,\n",
        "    'embeddings6_test': documentEmbeddings6_test\n",
        "}, DATA_PATH + 'embeddings6.joblib')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3OEw0YYwGnr"
      },
      "source": [
        "## Model 5: Neural Network on 3-embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFWLtNVGlHAs"
      },
      "outputs": [],
      "source": [
        "dataSplitted = np.load(DATA_PATH + 'dataSplitted.npz', allow_pickle=True)\n",
        "embeddings3 = joblib.load(DATA_PATH + \"embeddings3.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9AZl0FxlHAy"
      },
      "outputs": [],
      "source": [
        "X_train = embeddings3[\"embeddings3_train\"]\n",
        "X_val = embeddings3[\"embeddings3_val\"]\n",
        "X_test = embeddings3[\"embeddings3_test\"]\n",
        "\n",
        "y_train = dataSplitted[\"y_train\"]\n",
        "y_val = dataSplitted[\"y_val\"]\n",
        "y_test = dataSplitted[\"y_test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQy4aarUwU9v"
      },
      "outputs": [],
      "source": [
        "model5 = MLPClassifier(verbose=True, solver='adam', hidden_layer_sizes=(64, 64), random_state=1, activation=\"relu\")\n",
        "model5.n_jobs = -1\n",
        "model5.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBhUrXyawU9v"
      },
      "outputs": [],
      "source": [
        "#make prediction\n",
        "y_pred = model5.predict(X_val)\n",
        "\n",
        "print(\"accuracy: \", accuracy_score(y_val, y_pred))\n",
        "print(\"precision: \", precision_score(y_val, y_pred, average=\"binary\"))\n",
        "print(\"recall: \", recall_score(y_val, y_pred, average=\"binary\"))\n",
        "print(\"f1: \", f1_score(y_val, y_pred, average=\"binary\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "final test"
      ],
      "metadata": {
        "id": "-EFjqlP8FAV6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjhBH_y3E_0u"
      },
      "outputs": [],
      "source": [
        "#make prediction\n",
        "y_pred = model5.predict(X_test)\n",
        "\n",
        "print(\"accuracy: \", accuracy_score(y_test, y_pred))\n",
        "print(\"precision: \", precision_score(y_test, y_pred, average=\"binary\"))\n",
        "print(\"recall: \", recall_score(y_test, y_pred, average=\"binary\"))\n",
        "print(\"f1: \", f1_score(y_test, y_pred, average=\"binary\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHt7DrF55Z3q"
      },
      "outputs": [],
      "source": [
        "joblib.dump(model5, DATA_PATH + \"model5_advanced.joblib\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnS6V4Tg59JX"
      },
      "source": [
        "## Model 6: Neural Network on 6-embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CU4kbfkG59Ja"
      },
      "outputs": [],
      "source": [
        "dataSplitted = np.load(DATA_PATH + 'dataSplitted.npz', allow_pickle=True)\n",
        "embeddings6 = joblib.load(DATA_PATH + \"embeddings6.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34Lu3cx259Jb"
      },
      "outputs": [],
      "source": [
        "X_train = embeddings6[\"embeddings6_train\"]\n",
        "X_val = embeddings6[\"embeddings6_val\"]\n",
        "X_test = embeddings6[\"embeddings6_test\"]\n",
        "\n",
        "y_train = dataSplitted[\"y_train\"]\n",
        "y_val = dataSplitted[\"y_val\"]\n",
        "y_test = dataSplitted[\"y_test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lecq3NTx59Jc"
      },
      "outputs": [],
      "source": [
        "model6 = MLPClassifier(verbose=True, solver='adam', hidden_layer_sizes=(64, 64), random_state=1, activation=\"relu\")\n",
        "model6.n_jobs = -1\n",
        "model6.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Gq1RHum59Je"
      },
      "outputs": [],
      "source": [
        "#make prediction\n",
        "y_pred = model6.predict(X_val)\n",
        "\n",
        "print(\"accuracy: \", accuracy_score(y_val, y_pred))\n",
        "print(\"precision: \", precision_score(y_val, y_pred, average=\"binary\"))\n",
        "print(\"recall: \", recall_score(y_val, y_pred, average=\"binary\"))\n",
        "print(\"f1: \", f1_score(y_val, y_pred, average=\"binary\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "final test"
      ],
      "metadata": {
        "id": "7GMz4RbqGMDb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQLC0zNSFmGc"
      },
      "outputs": [],
      "source": [
        "#make prediction\n",
        "y_pred = model6.predict(X_test)\n",
        "\n",
        "print(\"accuracy: \", accuracy_score(y_test, y_pred))\n",
        "print(\"precision: \", precision_score(y_test, y_pred, average=\"binary\"))\n",
        "print(\"recall: \", recall_score(y_test, y_pred, average=\"binary\"))\n",
        "print(\"f1: \", f1_score(y_test, y_pred, average=\"binary\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIOtalvD59Jf"
      },
      "outputs": [],
      "source": [
        "joblib.dump(model6, DATA_PATH + \"model6_advanced.joblib\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM_W48LJuINd"
      },
      "source": [
        "## Model 7: Merge TFIDF Features and Embeddings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nl4GefKgnPns"
      },
      "outputs": [],
      "source": [
        "dataSplitted = np.load(DATA_PATH + 'dataSplitted.npz', allow_pickle=True)\n",
        "embeddings3 = joblib.load(DATA_PATH + \"embeddings3.joblib\")\n",
        "tfidf = joblib.load(DATA_PATH + \"tfidf.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pDvjEN7nPnu"
      },
      "outputs": [],
      "source": [
        "embeddings_train = embeddings3[\"embeddings3_train\"]\n",
        "embeddings_val = embeddings3[\"embeddings3_val\"]\n",
        "embeddings_test = embeddings3[\"embeddings3_test\"]\n",
        "\n",
        "tfidf_train = tfidf[\"tfidf_train\"]\n",
        "tfidf_val = tfidf[\"tfidf_val\"]\n",
        "tfidf_test = tfidf[\"tfidf_test\"]\n",
        "\n",
        "y_train = dataSplitted[\"y_train\"]\n",
        "y_val = dataSplitted[\"y_val\"]\n",
        "y_test = dataSplitted[\"y_test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdP0OGMy2jpb"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Combine the sparse matrices using hstack\n",
        "X_train = hstack([tfidf_train, csr_matrix(embeddings_train)])\n",
        "X_val = hstack([tfidf_val, csr_matrix(embeddings_val)])\n",
        "X_test = hstack([tfidf_test, csr_matrix(embeddings_test)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETE6WAt-tgdn"
      },
      "outputs": [],
      "source": [
        "\n",
        "model7 = MLPClassifier(alpha = 0.005, max_iter=11, verbose=True, solver='adam', hidden_layer_sizes=(128, 64), random_state=1, activation=\"relu\")\n",
        "model7.n_jobs = -1\n",
        "model7.fit(X_train[0:20000], y_train[0:20000])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model7.predict(X_val)"
      ],
      "metadata": {
        "id": "qGDzcOlwAPfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "experimenting with changing recall:"
      ],
      "metadata": {
        "id": "xMsj3NmKGWVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "probas = model7.predict_proba(X_val)[:, 1]\n"
      ],
      "metadata": {
        "id": "s7gMq7MYiKfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.copy(probas)\n",
        "threshold = 0.01\n",
        "y_pred[y_pred > threshold] = 1\n",
        "y_pred[y_pred <= threshold] = 0"
      ],
      "metadata": {
        "id": "BQ1FjKuul5qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "validation test"
      ],
      "metadata": {
        "id": "Nm4WzuJiGau6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"accuracy: \", accuracy_score(y_val, y_pred))\n",
        "print(\"precision: \", precision_score(y_val, y_pred, average=\"binary\"))\n",
        "print(\"recall: \", recall_score(y_val, y_pred, average=\"binary\"))\n",
        "print(\"f1: \", f1_score(y_val, y_pred, average=\"binary\"))"
      ],
      "metadata": {
        "id": "xVLazAcUgzLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "final test"
      ],
      "metadata": {
        "id": "0j9mCfl8GFfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model7.predict(X_test)\n",
        "print(\"accuracy: \", accuracy_score(y_test, y_pred))\n",
        "print(\"precision: \", precision_score(y_test, y_pred, average=\"binary\"))\n",
        "print(\"recall: \", recall_score(y_test, y_pred, average=\"binary\"))\n",
        "print(\"f1: \", f1_score(y_test, y_pred, average=\"binary\"))"
      ],
      "metadata": {
        "id": "UBIvM16pGE5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading models"
      ],
      "metadata": {
        "id": "XNudHoGLW_8X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This can be used instead of training again, just load and run the tests"
      ],
      "metadata": {
        "id": "V4MKwvzQXDkO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lieyZdfo5r7j"
      },
      "outputs": [],
      "source": [
        "joblib.dump(model7, DATA_PATH + \"model7_advanced.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZykLUcXOrjK-"
      },
      "outputs": [],
      "source": [
        "model1 = joblib.load(DATA_PATH + \"model1_advanced.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = joblib.load(DATA_PATH + \"model2_advanced.joblib\")"
      ],
      "metadata": {
        "id": "MFl5GxobW9t-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = joblib.load(DATA_PATH + \"model3_advanced.joblib\")"
      ],
      "metadata": {
        "id": "eQrjnKlZW720"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model4 = joblib.load(DATA_PATH + \"model4_advanced.joblib\")"
      ],
      "metadata": {
        "id": "YnbMwhXeW6_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model5 = joblib.load(DATA_PATH + \"model5_advanced.joblib\")"
      ],
      "metadata": {
        "id": "8e5_6hr9W5qW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model6 = joblib.load(DATA_PATH + \"model6_advanced.joblib\")"
      ],
      "metadata": {
        "id": "tniKuED8W4xA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model7 = joblib.load(\"/content/drive/MyDrive/Data/model7_advanced.joblib\")"
      ],
      "metadata": {
        "id": "7Ktz5aWMKpaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJ4ITMqTrkza"
      },
      "source": [
        "# Part 4: Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LIAR DATASET"
      ],
      "metadata": {
        "id": "f-Hbof0PVJHW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9d-XoS_PYNxN"
      },
      "outputs": [],
      "source": [
        "embeddingModel = KeyedVectors.load_word2vec_format(DATA_PATH + \"GoogleNews-vectors-negative300.bin\", binary=True, limit=1000000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDV0K6nKYNxP"
      },
      "outputs": [],
      "source": [
        "def documentEmbedN(tokens, n):\n",
        "    tokenLength = len(tokens)\n",
        "    # Pad the token length to have a minimum length of n\n",
        "    if tokenLength < n:\n",
        "        padding = np.array([''] * (n - tokenLength))\n",
        "        tokens = np.concatenate((tokens, padding))\n",
        "        tokenLength = n\n",
        "\n",
        "    vectorArrays = []\n",
        "    for i in range(n):\n",
        "        start_index = int(i * tokenLength / n)\n",
        "        end_index = int((i + 1) * tokenLength / n)\n",
        "\n",
        "        vectorArray = [embeddingModel[token] if token in embeddingModel else np.zeros(300)\n",
        "                       for token in tokens[start_index:end_index]]\n",
        "        vectorArrays.append(vectorArray)\n",
        "\n",
        "    means = []\n",
        "    for vectorArray in vectorArrays:\n",
        "        mean = np.mean(vectorArray, axis=0)\n",
        "        means.append(mean)\n",
        "\n",
        "    documentEmbed = np.concatenate(means, axis=0)\n",
        "\n",
        "    return documentEmbed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "liar = pd.read_csv(DATA_PATH + \"train_liar.tsv\", sep='\\t', header=None)"
      ],
      "metadata": {
        "id": "00t9eMhTS25W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "liar_falses = [\"half-true\", \"false\", \"barely-true\", \"pants-fire\"]\n",
        "liar_trues = [\"true\", \"mostly-true\"]"
      ],
      "metadata": {
        "id": "-5txiwS5U398"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "liar = liar[[1, 2]]\n",
        "liar.columns = [\"type\", \"content\"]\n"
      ],
      "metadata": {
        "id": "7SMVXv0mTUbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "liar['cleaned'] = liar['content'].progress_apply(clean_data_pipeline)\n"
      ],
      "metadata": {
        "id": "GcaFKbOrVvoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "liar['lengths'] = liar['content'].progress_apply(lambda tokens: len(tokenize(tokens)))"
      ],
      "metadata": {
        "id": "XnivkG_m1ew-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "liar[\"joined\"] = np.array(liar[\"cleaned\"].progress_apply(lambda tokens: ' '.join(tokens)))"
      ],
      "metadata": {
        "id": "Xakkoy4iJ9qG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "liar[\"joined\"]"
      ],
      "metadata": {
        "id": "QNo2LMKNWLQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grouping_rules(label):\n",
        "    if label in liar_falses:\n",
        "        return 1\n",
        "    elif label in liar_trues:\n",
        "        return 0\n",
        "    else:\n",
        "        raise Exception(\"Label is not in either fakes or reliables\")\n"
      ],
      "metadata": {
        "id": "O5kiV-2GWwtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "liar[\"type\"] = liar[\"type\"].apply(grouping_rules)"
      ],
      "metadata": {
        "id": "fIBAALR9W8Ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bow_vectorizer = joblib.load(DATA_PATH + \"bow.joblib\")[\"bow_vectorizer\"]\n",
        "tfidf_vectorizer = joblib.load(DATA_PATH + \"tfidf.joblib\")[\"tfidf_vectorizer\"]"
      ],
      "metadata": {
        "id": "PUXmS2_HXtsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baseline:"
      ],
      "metadata": {
        "id": "SVsh8mhSJlff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2_simple = joblib.load(DATA_PATH + \"model2_simple.joblib\")\n",
        "bow = bow_vectorizer.transform(liar[\"joined\"])"
      ],
      "metadata": {
        "id": "gzU5Poq8Jmu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#make prediction\n",
        "y_pred = model2_simple.predict(bow)\n",
        "\n",
        "print(\"accuracy: \", accuracy_score(liar[\"type\"], y_pred))\n",
        "print(\"precision: \", precision_score(liar[\"type\"], y_pred, average=\"binary\"))\n",
        "print(\"recall: \", recall_score(liar[\"type\"], y_pred, average=\"binary\"))\n",
        "print(\"f1: \", f1_score(liar[\"type\"], y_pred, average=\"binary\"))"
      ],
      "metadata": {
        "id": "LLF0lVgsKGbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(liar[\"type\"], y_pred, labels = [0, 1])\n",
        "tn, fp, fn, tp = confusion_matrix(liar[\"type\"], y_pred, labels = [0, 1]).ravel()\n",
        "\n",
        "print((tp, fp))\n",
        "print((fn, tn))"
      ],
      "metadata": {
        "id": "Nkl4yfMeb89X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Advanced:"
      ],
      "metadata": {
        "id": "Xgxrvjv9KypS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model7 = joblib.load(DATA_PATH + \"model7_advanced.joblib\")"
      ],
      "metadata": {
        "id": "xMRN7yiDK4yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = tfidf_vectorizer.transform(bow)\n",
        "embed3 = np.vstack(liar[\"cleaned\"].progress_apply(lambda tokens : documentEmbedN(tokens , 3)).values)"
      ],
      "metadata": {
        "id": "A2VGGW8GK7Ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = hstack([tfidf, csr_matrix(embed3)])"
      ],
      "metadata": {
        "id": "2lzdNbygLBsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#make prediction\n",
        "y_pred = model7.predict(X)\n",
        "\n",
        "print(\"accuracy: \", accuracy_score(liar[\"type\"], y_pred))\n",
        "print(\"precision: \", precision_score(liar[\"type\"], y_pred, average=\"binary\"))\n",
        "print(\"recall: \", recall_score(liar[\"type\"], y_pred, average=\"binary\"))\n",
        "print(\"f1: \", f1_score(liar[\"type\"], y_pred, average=\"binary\"))"
      ],
      "metadata": {
        "id": "RZnwodoWLoM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(liar[\"type\"], y_pred, labels = [0, 1])\n",
        "tn, fp, fn, tp = confusion_matrix(liar[\"type\"], y_pred, labels = [0, 1]).ravel()\n",
        "\n",
        "print((tp, fp))\n",
        "print((fn, tn))"
      ],
      "metadata": {
        "id": "7H2ThPIHfZrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boks:"
      ],
      "metadata": {
        "id": "y8NW2-KS11un"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a boxplot for the 'lengths' column\n",
        "liar.boxplot(column=\"lengths\", showfliers=False)"
      ],
      "metadata": {
        "id": "xrabpbTs1361"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "JCdgSINk0t8o",
        "SsqceovA0oBh"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
